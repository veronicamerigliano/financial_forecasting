{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26939589",
   "metadata": {},
   "source": [
    "# Loading libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988fe53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import datasets and load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import calendar\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score,mean_absolute_percentage_error\n",
    "\n",
    "\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "\n",
    "\n",
    "#if i want to see output not truncated add this:df.infor()\n",
    "pd.set_option('display.max_rows', None)   # Show all rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.width', None)  # Prevent line wrapping\n",
    "pd.set_option('display.max_colwidth', None) #show full column content\n",
    "\n",
    "codes = pd.read_csv ('codes.csv')\n",
    "df=pd.read_csv('USE_THIS.csv')\n",
    "\n",
    "print(df.sample(100))\n",
    "#looking good, theres negatives, all years, all months all good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe59bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop reference and preiod columns\n",
    "df.drop(columns=['reference', 'period', 'hours'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9dc327",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a propper date time column and fix april to be the 4th month instead of financial year\n",
    "#first convert payperiod to int\n",
    "df['fiscal_month'] = df['payperiod'].astype(int)\n",
    "\n",
    "#convert fiscal month to calendar month\n",
    "df['calendar_month'] = (df['fiscal_month'] + 3) % 12\n",
    "df['calendar_month'] = df['calendar_month'].replace({0: 12}) # march becomes 0\n",
    "\n",
    "# ajust year so everything happens in the same year\n",
    "df['calendar_year'] = df['year']\n",
    "df.loc[df['fiscal_month'] >= 10, 'calendar_year'] += 1\n",
    "\n",
    "#create a datetime object. just the 1st of each month since there isnt a specific day\n",
    "df['date'] = pd.to_datetime(df['calendar_year'].astype(str) + '-' + df['calendar_month'].astype(str) + '-01')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4101f50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"continuous_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85201eb6",
   "metadata": {},
   "source": [
    "# SARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adc49cb",
   "metadata": {},
   "source": [
    "SARIMA stands for Seasonal AutoRegressive Integrated Moving Average.\n",
    "It is a statistical model used for forecasting time series data, especially when the data shows seasonal patterns (like yearly or monthly cycles).\n",
    "- Good for interpretable, traditional time series forecasting.\n",
    "\n",
    "- Handles both short-term fluctuations and repeating seasonal cycles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6521537",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flagging covid years\n",
    "df['date'] = pd.to_datetime(df['date']) #just to be xtra sure its in datetime\n",
    "\n",
    "#flag COVID-affected dates\n",
    "df['covid_flag'] = (\n",
    "    (df['date'].dt.year == 2020) |\n",
    "    ((df['date'].dt.year == 2022) & (df['date'].dt.month <= 9))\n",
    ").astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d187219",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#graph showing amount over time\n",
    "df_ts = df.groupby('date')['amount'].sum().sort_index()\n",
    "\n",
    "(df_ts / 1e6).plot(title='Amount Over Time', figsize=(12,6))  #divided by 1e6 whihc means 1 000 000 (1 mil) so axis shows 1 2 3 \n",
    "plt.ylabel('Amount (Millions Â£)')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f1eaf8",
   "metadata": {},
   "source": [
    " ### SARIMA parameters\n",
    " (p, d, q) are the non-seasonal parameters:\n",
    " - p: number of lag observations included in the model (autoregressive part)\n",
    " - d: number of times the raw observations are differenced to make the series stationary\n",
    " - q: size of the moving average window (uses past forecast errors)\n",
    "\n",
    " (P, D, Q, s) are the seasonal parameters:\n",
    " - P: seasonal autoregressive order\n",
    " - D: seasonal differencing order\n",
    " - Q: seasonal moving average order\n",
    " - s: number of periods in each season (e.g. 12 for monthly data with yearly seasonality)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3f7976",
   "metadata": {},
   "source": [
    "\n",
    "### manually tune SARIMA parameters:\n",
    "to find out what d=\n",
    "1. use plots to understand if the series is already stationary\n",
    "2. plot the original series, and if the trend is removed after diff() then d=1. \n",
    "Now I need to find out p and q "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226276cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use plots to understand if the series is already stationary by comparing orignial time series to first differenced\n",
    "#plot the original series, if the trend is removed after .diff() then d = 1\n",
    "(df_ts / 1e6).plot(title='original time series', figsize=(12,6))\n",
    "plt.show()\n",
    "\n",
    "#first difference (d=1), \n",
    "df_ts_diff = df_ts.diff().dropna()\n",
    "(df_ts_diff / 1e6).plot(title='first differenced series', figsize=(12,6))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a50ee76",
   "metadata": {},
   "source": [
    "To find out what p and q are, use ACF and PACF plots\n",
    "\n",
    "PACF spikes = good for estimating p\n",
    "\n",
    "ACF spikes = good for estimating q\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fde492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#autocorrelation(ACF) and partial autocorrelation (PACF) to find out p and q\n",
    "#the 24 tells the function to shohw autocorrelations up to lag 20. \n",
    "#lag 24 covers short term dependencies (1-6 months) seasonal patterns (12 months) and longer term correlations (1+years)\n",
    "plot_acf(df_ts_diff, lags=24) \n",
    "plot_pacf(df_ts_diff, lags=24)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7c786d",
   "metadata": {},
   "source": [
    "It looks like in both graphs there are significantly non- zero sutocorrelations at lag 1\n",
    "ACF (q) = 1\n",
    "\n",
    "PACF (p) = 1\n",
    "The data is monthly so s=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd84cb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting seasonal differences, If this removes repeating yearly patterns then d=1for sure\n",
    "df_ts_seasonal_diff = df_ts.diff(12).dropna()\n",
    "df_ts_seasonal_diff.plot(title='seasonally differenced (12)', figsize=(12,6))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd5ba41",
   "metadata": {},
   "source": [
    "It looks like repeating yearly patterns were removed so \n",
    "\n",
    "d = 1\n",
    "\n",
    "p = 1\n",
    "\n",
    "q = 1\n",
    "\n",
    "s = 12\n",
    "The lower the AIC the bettert the  fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c917ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using parameters 1,1,1    1,1,1,12\n",
    "#worth trying with different combinations as well\n",
    "model1 = SARIMAX(df_ts,\n",
    "                order=(1,1,1), #(p, d, q) = non-seasonal ARIMA parameters\n",
    "                seasonal_order=(1,1,1,12),  # (P, D, Q, s) = seasonal ARIMA parameters and s= length of the seasonal cycle in this case 12 moths\n",
    "                enforce_stationarity=False,\n",
    "                enforce_invertibility=False)\n",
    "\n",
    "results1 = model1.fit()\n",
    "print(results1.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daedbbe3",
   "metadata": {},
   "source": [
    "### tune SARIMA parameters with a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b09652c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop to try different variations. \n",
    "for p in range(2):\n",
    "    for q in range(2):\n",
    "        for P in range(2):\n",
    "            for Q in range(2):\n",
    "                try:\n",
    "                    model = SARIMAX(df_ts,\n",
    "                                    order=(p,1,q),\n",
    "                                    seasonal_order=(P,1,Q,12),\n",
    "                                    enforce_stationarity=False,\n",
    "                                    enforce_invertibility=False)\n",
    "                    results = model.fit(disp=False)\n",
    "                    print(f'ARIMA({p},1,{q}) x ({P},1,{Q},12) - AIC:{results.aic}')\n",
    "                except:\n",
    "                    continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746d1497",
   "metadata": {},
   "source": [
    "Best fit is   0,1,1    0,1,1,12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eddd677",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best fit was so using those parameters (0,1,1)(0,1,1,12)\n",
    "model1 = SARIMAX(df_ts,\n",
    "                order=(0,1,1), #(p, d, q) = non-seasonal ARIMA parameters\n",
    "                seasonal_order=(0,1,1,12),  # (P, D, Q, s) = seasonal ARIMA parameters and s= length of the seasonal cycle in this case 12 moths\n",
    "                enforce_stationarity=False,\n",
    "                enforce_invertibility=False)\n",
    "\n",
    "results1 = model1.fit()\n",
    "print(results1.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3c22a0",
   "metadata": {},
   "source": [
    "### SARIMA Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163689d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#forecast the next 12 months\n",
    "pred = results.get_forecast(steps=12)\n",
    "pred_ci = pred.conf_int()\n",
    "\n",
    "#plot\n",
    "ax = (df_ts / 1e6).plot(label='Observed', figsize=(14, 6))\n",
    "(pred.predicted_mean / 1e6).plot(ax=ax, label='Forecast')\n",
    "\n",
    "ax.fill_between(pred_ci.index, \n",
    "                pred_ci.iloc[:, 0] / 1e6, \n",
    "                pred_ci.iloc[:, 1] / 1e6, \n",
    "                color='k', alpha=0.2)\n",
    "ax.set_title('SARIMA Forecast')\n",
    "ax.set_ylabel ('amount millions')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab98ef37",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb117aa",
   "metadata": {},
   "source": [
    "\n",
    "XGBoost builds a series of decision trees, where each tree tries to correct the mistakes made by the previous ones.\n",
    "\n",
    "1. Start with a simple prediction (e.g., average of all target values).\n",
    "\n",
    "2. Measure the errors (residuals) between predicted and actual values.\n",
    "\n",
    "3. Build a small decision tree to predict these errors.\n",
    "\n",
    "4. Update the prediction by adding the new tree's output (a correction).\n",
    "\n",
    "5. Repeat steps 2â4, adding one tree at a time, gradually improving the model.\n",
    "\n",
    "6. Stop when a set number of trees is reached or performance stops improving.\n",
    "\n",
    "Each tree is 'boosted' by learning from the previous ones â hence gradient boosting.- Very accurate and fast.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222b2165",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516b3617",
   "metadata": {},
   "source": [
    "1. add the CC and IJB budget page df and change names\n",
    "2. one hot encode the IJB budget pages\n",
    "3. flagging months with peaks\n",
    "4. encode categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5298a85",
   "metadata": {},
   "source": [
    "addding CC and ijb budget pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a14d221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean and standardize cost center codes\n",
    "codes = codes.rename(columns={'CC': 'cc', 'IJB Budget Page': 'ijb_budget_page'})\n",
    "codes['cc'] = codes['cc'].astype(str).str.strip().str.upper()\n",
    "codes = codes.drop_duplicates('cc')\n",
    "\n",
    "#merge ijb budget page onto df.\n",
    "df['cc'] = df['cc'].astype(str).str.strip().str.upper()\n",
    "df = df.merge(codes[['cc', 'ijb_budget_page']], on='cc', how='left', validate='many_to_one')\n",
    "\n",
    "# captrue the unique ijb budget levels\n",
    "budget_levels = sorted(codes['ijb_budget_page'].dropna().unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b453601",
   "metadata": {},
   "source": [
    "one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9437bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding ijb budget pages\n",
    "def add_budget_page_ohe(frame, levels):\n",
    "    if 'ijb_budget_page' not in frame.columns:\n",
    "        return frame\n",
    "    out = frame.copy()\n",
    "    cat = pd.Categorical(out['ijb_budget_page'], categories=levels)\n",
    "    dummies = pd.get_dummies(cat, prefix='ijb_budget_page', dummy_na=False).astype('uint8')\n",
    "    out = pd.concat([out.drop(columns=['ijb_budget_page']), dummies], axis=1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f582cd1c",
   "metadata": {},
   "source": [
    "flagging months with peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81c9204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set large payment months and build a month start flag.\n",
    "flag_months = ['2022-11', '2023-11', '2024-10', '2025-09']\n",
    "flag_starts = pd.to_datetime([m + '-01' if len(m) == 7 else m for m in flag_months])\n",
    "\n",
    "df = df.copy()\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['month_start'] = df['date'].values.astype('datetime64[M]')\n",
    "df['large_payment_flag'] = df['month_start'].isin(flag_starts).astype('uint8') #booleans fo is in flagged month \n",
    "\n",
    "print(\"flag counts (historical):\", df['large_payment_flag'].value_counts().to_dict())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66568357",
   "metadata": {},
   "source": [
    "Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688e00ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categoricals with label encoder\n",
    "categorical_cols = ['cc', 'payrollgroup', 'element', 'job']\n",
    "label_encoders = {}\n",
    "inv_mappings = {}\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "    inv_mappings[col] = {v: k for k, v in dict(zip(le.classes_, le.transform(le.classes_))).items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8024f1e9",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165dc996",
   "metadata": {},
   "source": [
    "\n",
    "splits dataset into training and test sets for both features = x and target = y\n",
    "\n",
    "parameters:\n",
    "- x = feature matrix (input data)\n",
    "- y = target vector (what i want to predict)\n",
    "- test_size=0.2 = reserves 20% of the data for testing\n",
    "- random_state=42 = ensures reproducible split\n",
    "\n",
    "Output:\n",
    "- X_train, y_train = used to train the model\n",
    "- x_test, y_test = used to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002095c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de61632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build time features then add budget page one hots.\n",
    "# pull standard calendar parts to support both calendar and fiscal \n",
    "df['calendar_year'] = df['date'].dt.year\n",
    "df['calendar_month'] = df['date'].dt.month\n",
    "\n",
    "\n",
    "# fixing fiscal months to calendar months\n",
    "# shift months back by 3 so apr becomes 1 and wrap around to 12\n",
    "df['fiscal_month'] = (df['date'].dt.month - 3) % 12\n",
    "df['fiscal_month'] = df['fiscal_month'].replace({0: 12})\n",
    "\n",
    "# label the fiscal year as the same calendar year for apr to dec \n",
    "df['year'] = np.where(df['date'].dt.month > 3, df['date'].dt.year, df['date'].dt.year - 1)\n",
    "\n",
    "# mirror of fiscal month for code that expects payperiod\n",
    "df['payperiod'] = df['fiscal_month']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611ecde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# makning covid flag\n",
    "df['covid_flag'] = ((df['date'].dt.year == 2020) | ((df['date'].dt.year == 2022) & (df['date'].dt.month <= 9))).astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec317466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time is a circle\n",
    "# cyclic month features\n",
    "# encode month on a circle so december and january are close \n",
    "df['mo_sin'] = np.sin(2 * np.pi * df['calendar_month'] / 12.0)\n",
    "df['mo_cos'] = np.cos(2 * np.pi * df['calendar_month'] / 12.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b7f1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add ijb budget page one hots.\n",
    "# expand categorical page into consistent dummy columns using fixed levels so train and future align.\n",
    "df = add_budget_page_ohe(df, budget_levels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65a9d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop helper date columns not used for modeling.\n",
    "for col in ['month_start', 'month_period']:\n",
    "    if col in df.columns:\n",
    "        df.drop(columns=[col], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38845b6d",
   "metadata": {},
   "source": [
    "Defining features to exclude the target (amount) and date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f348138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define feature list excluding target and raw date.\n",
    "# leave out amount because it is the target and date because we use derived parts instead.\n",
    "features = [c for c in df.columns if c not in ['amount', 'date']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42d4eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making things sturdier\n",
    "# remove duplicated column names to avoid weird inputs at fit time.\n",
    "dupe_cols = df.columns[df.columns.duplicated()].tolist()\n",
    "if dupe_cols:\n",
    "    print(\"Dropping duplicated columns:\", dupe_cols)\n",
    "    df = df.loc[:, ~df.columns.duplicated(keep='first')]\n",
    "\n",
    "# keep only features that still exist\n",
    "features = [c for c in features if c in df.columns]\n",
    "\n",
    "#  numeric inputs only\n",
    "# convert any remaining non numeric feature columns to category codes as a safe net\n",
    "bad = df[features].select_dtypes(exclude=['number', 'bool']).columns.tolist()\n",
    "for col in bad:\n",
    "    print(f\"Converting {col} from {df[col].dtype} to category codes\")\n",
    "    df[col] = pd.Categorical(df[col]).codes\n",
    "\n",
    "# ensure each feature name is present once\n",
    "features = list(dict.fromkeys(features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f259c6",
   "metadata": {},
   "source": [
    "Whatâs left becomes the input features (X) - like cc, subj, month etc\n",
    "\n",
    "splitting **training data**\n",
    "- x_train = input features for the model to learn from\n",
    "- y_train = the known historical target values (amounts),  used to train the model\n",
    "\n",
    "splitting **test data** \n",
    "- x_test = inputs for the future/prediction period\n",
    "- y_test = actual values for this futre period (used to evaluate model performance)\n",
    "\n",
    "SOOOO\n",
    "- the model learnspatterns from x_train to predict y_train \n",
    "- then it makes predictions on x_test\n",
    "- ten compare those predictions with y_test to see how well it performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd6f623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split by date.\n",
    "train_df = df[df['date'] < '2024-07-01'].copy()\n",
    "test_df = df[df['date'] >= '2024-07-01'].copy()\n",
    "\n",
    "X_train, y_train = train_df[features], train_df['amount']\n",
    "X_test, y_test = test_df[features], test_df['amount']\n",
    "\n",
    "# checkin that everything is numerrrrric\n",
    "print(\"Nonnumeric features:\", X_train.select_dtypes(exclude=['number', 'bool']).columns.tolist()) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2d944b",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55556c5d",
   "metadata": {},
   "source": [
    "| Parameter            | What It Does                                                                 | Effect with Large Data                                     | Suggested Value(s)           |\n",
    "|----------------------|------------------------------------------------------------------------------|-------------------------------------------------------------|-----------------------------|\n",
    "| `n_estimators`       | Number of boosting rounds (trees)                                            | More trees = better accuracy, but longer training           | 100â500 (start with 100) go up to 350 if performance is low   |\n",
    "| `max_depth`          | Maximum depth of each tree (model complexity)                                | Higher = more patterns learned, but overfitting risk        | 4â8 (start with 6)          |\n",
    "| `learning_rate`      | Shrinks the contribution of each tree (step size)                            | Lower rate = slower learning, but better generalization     | 0.05â0.1 is good for large data                    |\n",
    "| `subsample`          | Percentage of rows used per tree (row sampling)                              | Helps prevent overfitting by using partial data per tree    | use 0.8 or 0.7 to prevent overfitting        |\n",
    "| `colsample_bytree`   | Percentage of features used per tree (column sampling)                       | Reduces overfitting by ignoring some features each tree     | 0.7â0.9          |\n",
    "| `n_jobs`             | Number of CPU cores to use for training                                      | Controls parallelism â more cores = faster training         | -1 (use all CPU cores)      |\n",
    "| `tree_method`        | The algorithm XGBoost uses to grow trees                                     | Faster tree-growing methods help with big data              | 'hist' or 'gpu_hist'        |\n",
    "| `random_state`       | Sets a fixed seed for reproducibility                                        | Doesnât affect performance but ensures consistent results   | Any integer (e.g., 42)  for faster training on large data     |\n",
    "| `early_stopping_rounds` | Stops training if no improvement on validation set after N rounds         | Speeds up training and prevents overfitting                 | 10â20 with `eval_set` used  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e4c6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost model parameters.\n",
    "model = xgb.XGBRegressor(\n",
    "    n_estimators=350,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.7,\n",
    "    colsample_bytree=0.8,\n",
    "    n_jobs=-1,\n",
    "    tree_method='hist',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# fit and make test prediction\n",
    "model.fit(X_train, y_train)\n",
    "test_pred = model.predict(X_test)\n",
    "\n",
    "#checking that flags are being used\n",
    "print('flag in features?', 'large_payment_flag' in features)\n",
    "print('train flag counts:', train_df['large_payment_flag'].value_counts().to_dict())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd16b3e",
   "metadata": {},
   "source": [
    "### SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a15d10",
   "metadata": {},
   "source": [
    "SHAP (SHapley Additive exPlanations ) is a method to explain the output of machine learning models by assigning each feature an importance value for a particular prediction \n",
    "\n",
    "For each prediction, SHAP assigns each feature a value that shows how much it pushed the prediction higher or lower compared to the baseline (average prediction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba78ab0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHAP\n",
    "\n",
    "X_eval = X_test[features].copy()  # use test se\n",
    "X_eval = X_eval.sample(min(3000, len(X_eval)), random_state=42)\n",
    "X_eval = X_eval.fillna(0)\n",
    "\n",
    "\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3f8a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot of impactful features\n",
    "shap.summary_plot(shap_values, X_eval, plot_type='dot', max_display=10, show=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbcdd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# bar graph of most impactful features\n",
    "shap.summary_plot(shap_values, X_eval, plot_type='bar', max_display=10, show=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bfb7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#drill down into cc and subj\n",
    "# ensure there is a numoy array of shap values aligned with X_eval\n",
    "_sv = shap_values.values if hasattr(shap_values, 'values') else shap_values\n",
    "\n",
    "#shap df where columns match X_eval features and rows align to its observations\n",
    "shap_df = pd.DataFrame(_sv, columns=X_eval.columns, index=X_eval.index)\n",
    "\n",
    "\n",
    "#summary graph with shap impact stats on CC\n",
    "def shap_drilldown(col, pretty=None, top=15):\n",
    "    #Aggregate SHAP for one categorical feature by its category values\n",
    "    if col not in X_eval.columns or col not in shap_df.columns:\n",
    "        print(f'{col} not in features; skipping.')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    contrib = shap_df[col].values #get shap info from column\n",
    "    cats    = X_eval[col].values #get raw category (cats) codes for the column\n",
    "\n",
    "    #aggrefated cats summary table\n",
    "    tbl = (pd.DataFrame({col: cats, 'shap': contrib})\n",
    "           .groupby(col) #group rows by feature category\n",
    "           .agg(n=('shap','size'),\n",
    "                total_abs_SHAP=('shap', lambda x: np.abs(x).sum()),\n",
    "                mean_abs_SHAP=('shap', lambda x: np.abs(x).mean()),\n",
    "                mean_SHAP=('shap','mean'))\n",
    "           .reset_index())\n",
    "\n",
    "    #calculating each cat share of shap importancwe\n",
    "    total_abs = np.abs(contrib).sum()\n",
    "    tbl['share_%'] = 100.0 * tbl['total_abs_SHAP'] / (total_abs if total_abs > 0 else np.nan)\n",
    "\n",
    "    #to rename\n",
    "    name_col = pretty or col\n",
    "    tbl.rename(columns={col: name_col}, inplace=True)\n",
    "\n",
    "    # unencode names and if it fails just leaving them as they are\n",
    "    if 'inv_mappings' in globals() and col in inv_mappings:\n",
    "        tbl[name_col] = tbl[name_col].map(inv_mappings[col]).fillna(tbl[name_col])\n",
    "    elif 'label_encoders' in globals() and col in label_encoders:\n",
    "        try:\n",
    "            tbl[name_col] = label_encoders[col].inverse_transform(tbl[name_col].astype(int))\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # rank by overall impact and keep top N\n",
    "    tbl = tbl.sort_values('total_abs_SHAP', ascending=False).head(top)\n",
    "\n",
    "    # horizontal bar chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(tbl[name_col].astype(str)[::-1], tbl['total_abs_SHAP'][::-1])\n",
    "    plt.xlabel('Total (SHAP)')\n",
    "    plt.title(f'{name_col}  overall impact (SHAP)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # summary table\n",
    "    print(tbl[[name_col, 'n', 'total_abs_SHAP', 'mean_abs_SHAP', 'mean_SHAP', 'share_%']].to_string(index=False))\n",
    "    return tbl\n",
    "\n",
    "# Run for cc and subj\n",
    "cc_impact   = shap_drilldown('cc',   pretty='cc',   top=15)\n",
    "subj_impact = shap_drilldown('subj', pretty='subj', top=15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f70b3b",
   "metadata": {},
   "source": [
    "### Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e69602",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. A helper _month_start makes sure any date or timestamp is snapped to the first day of that month.\n",
    "\n",
    "2. A helper _ensure_encodings_inplace checks if label encoders exist and, if so,  applies them to any object-type columns in a DataFrame so categories are turned into numeric codes.\n",
    "\n",
    "3. A helper _add_date_features takes a dataset and a chosen future month, then stamps that month onto every row and rebuilds all the date-related features (calendar year, fiscal month, pay period, COVID flag, sine/cosine month cycle).\n",
    "\n",
    "4. A helper _to_month_start is used to clean and normalize input dates (including blanks or nulls) to the first of the month.\n",
    "\n",
    "5. The function prepare_future_adjustments_from_table reads a table of adjustment rules (like manual overrides or fixed amounts) and converts it into a standard list of dictionaries that the forecasting function can use.\n",
    "\n",
    "6. Inside this function, it keeps only active rules, cleans up the start and end dates, and fills in missing columns (kind, value) if theyâre not present.\n",
    "\n",
    "7. For each row, it determines whether the rule applies globally or to a specific cost centre, encoding CC IDs if needed.\n",
    "\n",
    "8. It figures out whether the adjustment is an absolute amount, an additive adjustment, or a legacy percent, and extracts the correct value.\n",
    "\n",
    "9. It collects all valid rules into a list of dictionaries with the same keys (start, end, cc_enc, kind, value) and returns that list for use in forecasting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0652d85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# snap any timestamp to the first day of its month\n",
    "def _month_start(ts):\n",
    "    ts = pd.to_datetime(ts)\n",
    "    return pd.Timestamp(ts.year, ts.month, 1)\n",
    "# apply fitted label encoders to object columns\n",
    "def _ensure_encodings_inplace(df_like, encoders):\n",
    "    if not encoders:\n",
    "        return df_like\n",
    "    # only transform columns that exist and are object dtype\n",
    "    for col, le in encoders.items():\n",
    "        if col in df_like.columns and df_like[col].dtype == 'O':\n",
    "            df_like[col] = le.transform(df_like[col].astype(str))\n",
    "    return df_like\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d58fcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stamp a single future month onto a copy and rebuild date features to match training.\n",
    "def _add_date_features(frame, future_month_start):\n",
    "    #  timestamp representing the first of the month\n",
    "    fm = pd.Timestamp(future_month_start)\n",
    "    # fiscal month with april as month one\n",
    "    fiscal_month = (fm.month - 3) % 12 or 12\n",
    "    # work on a copy \n",
    "    out = frame.copy()\n",
    "    # set the date to the future month for all rows\n",
    "    out['date'] = fm\n",
    "    # basic calendar parts\n",
    "    out['calendar_year'] = fm.year\n",
    "    out['calendar_month'] = fm.month\n",
    "    # fiscal month and related tags\n",
    "    out['fiscal_month'] = fiscal_month\n",
    "    out['year'] = fm.year if fm.month > 3 else fm.year - 1\n",
    "    out['payperiod'] = fiscal_month\n",
    "    # covid period marker\n",
    "    out['covid_flag'] = int((fm.year == 2020) or ((fm.year == 2022) and (fm.month <= 9)))\n",
    "    # redo cyclic month features\n",
    "    if 'mo_sin' in out.columns and 'mo_cos' in out.columns:\n",
    "        out['mo_sin'] = np.sin(2 * np.pi * out['calendar_month'] / 12.0)\n",
    "        out['mo_cos'] = np.cos(2 * np.pi * out['calendar_month'] / 12.0)\n",
    "    \n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f607b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers to read/normalise/encode the adjustments table \n",
    "def _to_month_start(x):\n",
    "    if x is None or (isinstance(x, float) and pd.isna(x)) or (isinstance(x, str) and not x.strip()):\n",
    "        return None\n",
    "    ts = pd.to_datetime(x)\n",
    "    return pd.Timestamp(ts.year, ts.month, 1)\n",
    "\n",
    "def prepare_future_adjustments_from_table(adj_df, label_encoders=None):\n",
    "\n",
    "    #normalises adjustments into a list of dicts the forecast function understands\n",
    "\n",
    "    def _to_month_start(v):\n",
    "        if v is None or (isinstance(v, float) and pd.isna(v)) or (isinstance(v, str) and v.strip() == ''):\n",
    "            return None\n",
    "        ts = pd.to_datetime(v)\n",
    "        return pd.Timestamp(ts.year, ts.month, 1)\n",
    "\n",
    "    df = adj_df.copy()\n",
    "\n",
    "    # keep only active rows\n",
    "    if 'active' in df.columns:\n",
    "        df = df[df['active'] == True].copy()\n",
    "\n",
    "    # parse dates\n",
    "    df['start'] = df['start'].apply(_to_month_start)\n",
    "    if 'end' in df.columns:\n",
    "        df['end'] = df['end'].apply(_to_month_start)\n",
    "    else:\n",
    "        df['end'] = None\n",
    "\n",
    "    # normalies missing columns\n",
    "    if 'kind' not in df.columns:\n",
    "        df['kind'] = np.nan\n",
    "    if 'value' not in df.columns:\n",
    "        df['value'] = np.nan\n",
    "\n",
    "    out = []\n",
    "    le_cc = (label_encoders or {}).get('cc')\n",
    "\n",
    "    for _, r in df.iterrows():\n",
    "        # figure out scope -> cc_enc\n",
    "        scope = str(r.get('scope', '')).lower()\n",
    "        key = r.get('key', None)\n",
    "\n",
    "        if scope == 'global':\n",
    "            cc_enc = None\n",
    "        elif scope == 'cc':\n",
    "            if le_cc is not None:\n",
    "                # only transform if key exists in encoder. else skip\n",
    "                try:\n",
    "                    cc_enc = le_cc.transform([key])[0]\n",
    "                except Exception:\n",
    "                    # unknown CC label - skip this row\n",
    "                    continue\n",
    "            else:\n",
    "                # no encoder provided - skip CC rule\n",
    "                continue\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        # determine kind/value\n",
    "        kind = str(r.get('kind', '')).strip().lower()\n",
    "        val = r.get('value', np.nan)\n",
    "\n",
    "        if kind in ('amount', 'adjustment'):\n",
    "            try:\n",
    "                value = float(val)\n",
    "            except Exception:\n",
    "                continue\n",
    "        else:\n",
    "            # #fix percentage problem from before \n",
    "            if 'pct' in df.columns and pd.notna(r.get('pct', np.nan)):\n",
    "                kind = 'percent'\n",
    "                try:\n",
    "                    value = float(r['pct'])  # 0.10 is 10%\n",
    "                except Exception:\n",
    "                    continue\n",
    "            else:\n",
    "                \n",
    "                continue\n",
    "\n",
    "        out.append({\n",
    "            'start': r['start'],\n",
    "            'end': r['end'],\n",
    "            'cc_enc': cc_enc,\n",
    "            'kind': kind,     \n",
    "            'value': value,   # absolute for amount/adjustment and fraction for percent\n",
    "        })\n",
    "\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95237352",
   "metadata": {},
   "source": [
    "This very long function forecasts the next N months by reusing the exact set of row tthat existed in the dame month last year (the panel), only updating the date fields and then running the trained model to get row by row predictions. it then sums those row predictinos to monthly totals and adds some checks.\n",
    "\n",
    "step by step:\n",
    "\n",
    "1. inputs\n",
    "- df: all historical data (must include date and amount)\n",
    "\n",
    "- model: the trained XGBoost \n",
    "\n",
    "- features: the exact columns the model expects (everything that it has been trained on, excluding amount and date).\n",
    "\n",
    "- horizon_months: how many months to forecast\n",
    "\n",
    "- start_from: last historical month to anchor the forecast (defaults to the last month in df)\n",
    "\n",
    "- label_encoders: dict for turning categorical strings into the same codes used in training\n",
    "\n",
    "- drift_rate_per_month:  grow/shrink the panel size a little each month (e.g., +3%)\n",
    "\n",
    "- trend_scaling: can apply a gentle year-over-year scaling factor learned from history\n",
    "\n",
    "- trend_clip: caps that YoY factor so it canât swing wildly\n",
    "\n",
    "- warn_tolerance: if the future panel size differs too much from the base month, adds a warning note.\n",
    "\n",
    "2. Set up. data is copied and definitely datetime. builds a list of future months (1st of each month)\n",
    "\n",
    "3. when trend scaling=true then do some math stuff that nudges predictions up/down a bit for realism\n",
    "\n",
    "4. forecast loop (once per each future month)\n",
    "- Pick the base panel: take all rows from the same month last year. If thatâs empty, fall back to the previous month. If still empty, skip this month and record a note.\n",
    "\n",
    "- Optional drift: if drift_rate_per_month â  0, randomly duplicate (growth) or drop (decline) some rows to simulate headcount/mix drift.\n",
    "\n",
    "- Update time features: call _add_date_features(base_rows, fm) to rewrite date-based columns (e.g., calendar/fiscal month, year, etc.) to the future month.\n",
    "\n",
    "- Remove target: drop amount so it doesnt leak the answer into the model.\n",
    "\n",
    "- Encode categoricals (if needed): _ensure_encodings_inplace applies the saved label encoders so category codes match training.\n",
    "\n",
    "- Align features: reindex(columns=features, fill_value=0) ensures the prediction frame has exactly the same columns the model expects (adds any missing as 0, drops extras).\n",
    "\n",
    "- Predict per row: model.predict(X_future) returns a prediction for each row in the panel.\n",
    "\n",
    "-  trend scaling: if enabled, multiply those predictions by the YoY factor for the base month (capped to trend_clip).\n",
    "\n",
    "- Store results: save the row-level predictions with the future month_start. Record diagnostics about panel sizes and any warnings.\n",
    "\n",
    "5. aggregate and return\n",
    " - concatenates all row evel predictions into future_detail\n",
    " - sums by month_start to get future_monthyl['predicted toatal']\n",
    " - merge in the diagnostics \n",
    " - return\n",
    "    - future_detial : every predicted row for every future month\n",
    "    - one row per month with the total forecast and sanity check info\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06338305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast engine using same month last year with full panel swaps\n",
    "def forecast_same_month_last_year(\n",
    "    df_hist,\n",
    "    model,\n",
    "    features,\n",
    "    horizon_months=12,\n",
    "    start_from=None,\n",
    "    label_encoders=None,\n",
    "    drift_rate_per_month=0.0,\n",
    "    trend_scaling=False,\n",
    "    trend_clip=(0.9, 1.1),\n",
    "    random_state=42,\n",
    "    warn_tolerance=0.15,\n",
    "    full_panel_swaps=None,\n",
    "    add_budget_page_ohe_fn=None,\n",
    "    budget_levels=None,\n",
    "    flag_starts=None,\n",
    "    future_adjustments=None,   \n",
    "):                         \n",
    "\n",
    "    # make a working copy and ensure date is datetime.\n",
    "    dfh = df_hist.copy()\n",
    "    dfh['date'] = pd.to_datetime(dfh['date'])\n",
    "\n",
    "    #choose the anchor month as the last month present if its not there\n",
    "    if start_from is None:\n",
    "        start_from = _month_start(dfh['date'].max())\n",
    "\n",
    "\n",
    "    #normalised map of future month to source month for full panel swaps\n",
    "    swap_map = {}\n",
    "    if full_panel_swaps:\n",
    "        for k, v in full_panel_swaps.items():\n",
    "            k0 = _month_start(k)\n",
    "            v0 = _month_start(v)\n",
    "            swap_map[k0] = v0\n",
    "\n",
    "    #build a set of months that shloud carry the large payment flag\n",
    "    flag_set = set(pd.to_datetime(flag_starts)) if flag_starts is not None else set()\n",
    "\n",
    "\n",
    "    #bumber future months starting one month after the anchor\n",
    "    future_months = pd.date_range(\n",
    "        start=start_from + relativedelta(months=1),\n",
    "        periods=horizon_months,\n",
    "        freq='MS'\n",
    "    )\n",
    "\n",
    "    #  yoy trend scaling factor by month\n",
    "    if trend_scaling:\n",
    "        hist_m = dfh['date'].values.astype('datetime64[M]')\n",
    "        monthly_actual = dfh.groupby(hist_m)['amount'].sum().sort_index()\n",
    "        yoy_factor = (monthly_actual / monthly_actual.shift(12)).dropna()\n",
    "    else:\n",
    "        yoy_factor = pd.Series(dtype=float)\n",
    "\n",
    "    # rng for drift %\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    rows_out, diag = [], []\n",
    "\n",
    "    # ensure historical object columns are encoded before slicing\n",
    "    _ensure_encodings_inplace(dfh, label_encoders)\n",
    "\n",
    "    prepared_adj = future_adjustments or []\n",
    "\n",
    "\n",
    "    #iterate one future month at a time and build a forecast panel\n",
    "    for fm in future_months:\n",
    "        mult = None\n",
    "        # pick the base month either from swap map or same month last year\n",
    "        if fm in swap_map:\n",
    "            base_start = swap_map[fm]\n",
    "        else:\n",
    "            base_start = _month_start(fm - relativedelta(years=1))\n",
    "        base_end = base_start + relativedelta(months=1)\n",
    "\n",
    "        # take the base month rows from history\n",
    "        base_rows = dfh[(dfh['date'] >= base_start) & (dfh['date'] < base_end)].copy()\n",
    "\n",
    "        #if empty then fall back to previous month\n",
    "        if base_rows.empty:\n",
    "            prev_start = _month_start(fm - relativedelta(months=1))\n",
    "            prev_end = prev_start + relativedelta(months=1)\n",
    "            base_rows = dfh[(dfh['date'] >= prev_start) & (dfh['date'] < prev_end)].copy()\n",
    "            base_start = prev_start\n",
    "\n",
    "        #if still empty then skip this month\n",
    "        if base_rows.empty:\n",
    "            diag.append({\n",
    "                'month_start': fm,\n",
    "                'base_month': base_start,\n",
    "                'base_rowcount': 0,\n",
    "                'future_rowcount': 0,\n",
    "                'note': 'no base panel skipped'\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        base_count = len(base_rows)\n",
    "\n",
    "        #apply drift to row count\n",
    "        if drift_rate_per_month != 0.0:\n",
    "            delta = int(round(base_count * drift_rate_per_month))\n",
    "            if delta > 0:\n",
    "                add_ix = rng.integers(0, base_count, size=delta)\n",
    "                base_rows = pd.concat([base_rows, base_rows.iloc[add_ix].copy()], ignore_index=True)\n",
    "            elif delta < 0:\n",
    "                keep_ix = rng.choice(base_count, size=base_count + delta, replace=False)\n",
    "                base_rows = base_rows.iloc[keep_ix].copy().reset_index(drop=True)\n",
    "\n",
    "        # stamp the future month date features onto the base panel\n",
    "        fut_rows = _add_date_features(base_rows, fm)\n",
    "        if 'amount' in fut_rows.columns:\n",
    "            fut_rows = fut_rows.drop(columns=['amount'])\n",
    "\n",
    "        #set the large payment flag for this future month\n",
    "        fut_rows['large_payment_flag'] = np.uint8(pd.Timestamp(fm) in flag_set)\n",
    "\n",
    "        #ensure encodings are applied after any new object cols slip in\n",
    "        _ensure_encodings_inplace(fut_rows, label_encoders)\n",
    "\n",
    "        #add one hots for ijb budget page so columns align with training\n",
    "        if add_budget_page_ohe_fn and (budget_levels is not None):\n",
    "            fut_rows = add_budget_page_ohe_fn(fut_rows, budget_levels)\n",
    "\n",
    "        mult = None  # reset per month\n",
    "        # align to training feature set and predict\n",
    "        X_future = fut_rows.reindex(columns=features, fill_value=0)\n",
    "        preds = model.predict(X_future)\n",
    "\n",
    "        # apply future adjustments\n",
    "        if prepared_adj:\n",
    "            applicable = []\n",
    "            for a in prepared_adj:\n",
    "                if a['start'] is None:\n",
    "                    continue\n",
    "                if (a['end'] is None and fm >= a['start']) or (\n",
    "                    a['end'] is not None and a['start'] <= fm <= a['end']\n",
    "                ):\n",
    "                    applicable.append(a)\n",
    "\n",
    "        if applicable:\n",
    "            mult = np.ones(len(preds), dtype=float)\n",
    "\n",
    "            # helper: scale a mask of rows so their sum hits a target amount\n",
    "            def _scale_to_amount(mask, target, arr):\n",
    "                cur = float(arr[mask].sum())\n",
    "                if cur <= 0 and target > 0:\n",
    "                    # nothing to scale from -  evenly spread across masked rows\n",
    "                    n = int(mask.sum())\n",
    "                    if n > 0:\n",
    "                        add_each = target / n\n",
    "                        arr[mask] = add_each\n",
    "                    return\n",
    "                if cur == 0:\n",
    "                    return  # both zero (or target==0) nothing to do\n",
    "                factor = target / cur\n",
    "                arr[mask] = arr[mask] * factor\n",
    "\n",
    "            #apply each applicable rule\n",
    "            for a in applicable:\n",
    "                # expected fields now :\n",
    "                # a['kind'] in {'amount', 'adjutment'}  (adjustment is optional; amount is main)\n",
    "                #a['cc_enc'] is None for global, else encoded CC id\n",
    "                #a['value'] holds the whole-number target (for 'amount') or change (for 'adjustment')\n",
    "\n",
    "                kind = str(a.get('kind', 'amount')).lower()\n",
    "                val  = float(a.get('value', 0.0))\n",
    "\n",
    "                if a['cc_enc'] is None:\n",
    "                    # global scope\n",
    "                    if kind == 'amount':\n",
    "                        _scale_to_amount(np.ones(len(preds), dtype=bool), val, preds)\n",
    "                    elif kind == 'adjustment':\n",
    "                        tgt = float(preds.sum()) + val\n",
    "                        _scale_to_amount(np.ones(len(preds), dtype=bool), tgt, preds)\n",
    "                else:\n",
    "                    #cc specific scope\n",
    "                    mask = (fut_rows['cc'].values == a['cc_enc'])\n",
    "                    if not mask.any():\n",
    "                        continue\n",
    "                    if kind == 'amount':\n",
    "                        _scale_to_amount(mask, val, preds)\n",
    "                    elif kind == 'adjustment':\n",
    "                        tgt = float(preds[mask].sum()) + val\n",
    "                        _scale_to_amount(mask, tgt, preds)\n",
    "\n",
    "        \n",
    "\n",
    "        # apply yoy scaling at the month level\n",
    "        if trend_scaling and not yoy_factor.empty:\n",
    "            tf = yoy_factor.get(base_start, 1.0)\n",
    "            if pd.isna(tf):\n",
    "                tf = 1.0\n",
    "            preds = preds * float(np.clip(tf, trend_clip[0], trend_clip[1]))\n",
    "\n",
    "        #collect detailed rows and diagnostics for this month.\n",
    "        fut_rows_out = fut_rows.copy()\n",
    "        fut_rows_out['month_start'] = fm\n",
    "        fut_rows_out['predicted_amount'] = preds\n",
    "        rows_out.append(fut_rows_out)\n",
    "\n",
    "        applied_factor = float(np.nan) if mult is None else float(np.mean(mult))\n",
    "        diag.append({\n",
    "            'month_start': fm,\n",
    "           'base_month': base_start,\n",
    "           'base_rowcount': int(base_count),\n",
    "          'future_rowcount': int(len(fut_rows_out)),\n",
    "            'note': ('full panel swap from ' + str(base_start.date())) if (fm in swap_map) else '',\n",
    "            'applied_factor': applied_factor,\n",
    "    })\n",
    "\n",
    "\n",
    "    # assemble the detail fram eand monthly totals\n",
    "    future_detail = pd.concat(rows_out, ignore_index=True) if rows_out else pd.DataFrame()\n",
    "    if not future_detail.empty:\n",
    "        future_monthly = (\n",
    "            future_detail.groupby('month_start', as_index=False)['predicted_amount']\n",
    "            .sum()\n",
    "            .rename(columns={'predicted_amount': 'predicted_total'})\n",
    "        )\n",
    "    else:\n",
    "        future_monthly = pd.DataFrame(columns=['month_start', 'predicted_total'])\n",
    "\n",
    "    # merge diagnostics onto the monthly totals for transparency\n",
    "    diag_df = pd.DataFrame(diag).sort_values('month_start')\n",
    "    future_monthly = future_monthly.merge(diag_df, on='month_start', how='right')\n",
    "\n",
    "    # return both the detailed panel and the monthly summary\n",
    "    return future_detail, future_monthly\n",
    "\n",
    "# configure full panel swaps\n",
    "full_swaps = {\n",
    "    '2025-09': '2023-11',\n",
    "    '2025-10': '2024-09'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b1731a",
   "metadata": {},
   "source": [
    "\n",
    "- There are 2 options for 'kind': amount and adjustment.\n",
    "    - amount: this would make the value inputted for eg. cc L12345 an exact amount. so if it originally was 60001 and the input value is now 60000, that makes cc L12345 60000 not 120000\n",
    "    - adjustment: on the other hand adjustment means that the number inputed adds or subtracts from the existing value. so if the originally cc 12345 was 10000 and the value input is -7000, that makes cc L12345 3000 not -7000\n",
    "- if the date is for example from 10/2025 to 01/2026, the value inputed is for each month.\n",
    "    - eg.  {'id':'ADJ-003','active':True,'scope':'global','key':'','start':'2026-02','end':'2026-04,'kind':'adjustment','value':25000,'note':'+25k ongoing'}\n",
    "    - there is an overall ('global' - on summed total amount) increase of 25k for each month from feb 2026 to apr 2026. so feb total + 25k, mar total + 25k, apr total +25k\n",
    "\n",
    "\n",
    "- making the table inline but in future it could be a csv or excel doc being loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dfe6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# making the table inline but in future it could be a csv or excel doc being loaded\n",
    "# eg: one CC fixed to an exact amount for 2026-01,\n",
    "# and a global +25,000 from 2026-02 onward for each month.\n",
    "adjustments_tbl = pd.DataFrame([\n",
    "    {'id':'ADJ-001','active':True,'scope':'cc','key':'L091722','start':'2026-01','end':'2026-01','kind':'amount','value':359787,'note':'Locked amount for CC L091722'},\n",
    "    {'id':'ADJ-003','active':True,'scope':'global','key':'','start':'2026-02','end':None,'kind':'adjustment','value':25000,'note':'+25k ongoing'}\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827818da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#convert the table to rules the model can use\n",
    "future_adjustments = prepare_future_adjustments_from_table(adjustments_tbl, label_encoders)\n",
    "\n",
    "\n",
    "#rules into existing forecast function\n",
    "future_detail, future_monthly = forecast_same_month_last_year(\n",
    "    df_hist=df,\n",
    "    model=model,\n",
    "    features=features,\n",
    "    horizon_months=12,\n",
    "    label_encoders=label_encoders,\n",
    "    drift_rate_per_month=0.0,\n",
    "    trend_scaling=False,\n",
    "    full_panel_swaps=full_swaps,\n",
    "    add_budget_page_ohe_fn=add_budget_page_ohe,\n",
    "    budget_levels=budget_levels,\n",
    "    flag_starts=flag_starts,\n",
    "    future_adjustments=future_adjustments,  \n",
    ")\n",
    "\n",
    "# quick sanity check for a month that was swapped\n",
    "print(\n",
    "    future_monthly.loc[\n",
    "        future_monthly['month_start'].isin(pd.to_datetime(['2025-09-01'])),\n",
    "        ['month_start', 'base_month', 'predicted_total', 'note']\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7787cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# making sure the detailed output has a month_start for joins\n",
    "if 'month_start' not in future_detail.columns:\n",
    "    future_detail['month_start'] = future_detail['date'].values.astype('datetime64[M]')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1aedd9",
   "metadata": {},
   "source": [
    "### actual vs predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f33fc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# compare actual vs predicted on the test period\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#carrying predictions alongside actuals\n",
    "test_eval = test_df.copy()\n",
    "test_eval['predicted_amount'] = y_pred\n",
    "test_eval['month_start'] = test_eval['date'].values.astype('datetime64[M]')\n",
    "\n",
    "#aggregate to monthly totals for actual and predicted\n",
    "monthly_actual = test_eval.groupby('month_start', as_index=False)['amount'].sum()\n",
    "monthly_pred = test_eval.groupby('month_start', as_index=False)['predicted_amount'].sum()\n",
    "\n",
    "#join the two series and keep a clean time order\n",
    "monthly_cmp = monthly_actual.merge(monthly_pred, on='month_start', how='outer').sort_values('month_start')\n",
    "\n",
    "# filter to a fixed comparison window.\n",
    "start_month = pd.Timestamp('2024-07-01')\n",
    "end_month = pd.Timestamp('2025-07-01')\n",
    "monthly_cmp = monthly_cmp[(monthly_cmp['month_start'] >= start_month) & (monthly_cmp['month_start'] <= end_month)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6a31ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot monthly actual and predicted\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(monthly_cmp['month_start'], monthly_cmp['amount'] / 1e6, marker='o', label='Actual')\n",
    "plt.plot(monthly_cmp['month_start'], monthly_cmp['predicted_amount'] / 1e6, marker='o', label='Predicted')\n",
    "plt.xlabel('month')\n",
    "plt.ylabel('total amount mil Â£')\n",
    "plt.title('actual vs predicted monthly total amount')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72681024",
   "metadata": {},
   "source": [
    "### forecast vs. budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e371bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# budget spec for august 2025 to march 2026.\n",
    "budget_spec = {\n",
    "    'months': ['August', 'September', 'October', 'November', 'December', 'January', 'February', 'March'],\n",
    "    'budget': [6819650.00, 9826859.00, 5453353.00, 5484053.00, 5463045.00, 5484052.00, 5473551.00, 5484530.00]\n",
    "}\n",
    "budgets_df = pd.DataFrame(budget_spec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd21b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# map budget month names to month starts aligned to the forecast start\n",
    "start_forecast = pd.to_datetime(future_monthly['month_start']).min()\n",
    "month_to_num = {m: i for i, m in enumerate(calendar.month_name) if m}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454ecc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# build a sequence of concrete month starts while rolling over year boundaries\n",
    "assigned_dates = []\n",
    "prev_ts = None\n",
    "for name in budgets_df['months']:\n",
    "    mnum = month_to_num[name]\n",
    "    if prev_ts is None:\n",
    "        year = start_forecast.year if mnum >= start_forecast.month else start_forecast.year + 1\n",
    "        ts = pd.Timestamp(year, mnum, 1)\n",
    "    else:\n",
    "        year = prev_ts.year\n",
    "        if mnum <= prev_ts.month:\n",
    "            year += 1\n",
    "        ts = pd.Timestamp(year, mnum, 1)\n",
    "    assigned_dates.append(ts)\n",
    "    prev_ts = ts\n",
    "\n",
    "budgets_df['month_start'] = assigned_dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd76ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# merge budgets with forecast totals and keep only budgeted months.\n",
    "plot_df = budgets_df.merge(\n",
    "    future_monthly[['month_start', 'predicted_total']],\n",
    "    on='month_start',\n",
    "    how='left'\n",
    ").sort_values('month_start')\n",
    "\n",
    "# drop any budget months that lie outside the forecast \n",
    "missing = plot_df['predicted_total'].isna().sum()\n",
    "if missing:\n",
    "    print(f\"Warning: {missing} budget month(s) are outside the forecast horizon and will be excluded.\")\n",
    "    plot_df = plot_df.dropna(subset=['predicted_total'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd9a4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# variance metrics for each month.\n",
    "y_label = 'Amount'\n",
    "title_suffix = ''\n",
    "plot_df['variance'] = plot_df['predicted_total'] - plot_df['budget']\n",
    "plot_df['variance_%'] = 100 * plot_df['variance'] / plot_df['budget'].replace(0, pd.NA)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130e6001",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot forecast versus budget over the budget window\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(plot_df['month_start'], plot_df['predicted_total'], marker='o', label='Forecast')\n",
    "plt.plot(plot_df['month_start'], plot_df['budget'], marker='o', label='Budget')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel(y_label)\n",
    "plt.title('Forecast vs Budget' + title_suffix)\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# print a neat variance table for quick review.\n",
    "out_cols = ['month_start', 'budget', 'predicted_total', 'variance', 'variance_%']\n",
    "print(\"\\nForecast vs Budget variance:\")\n",
    "print(plot_df[out_cols].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11d9575",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d25e24",
   "metadata": {},
   "source": [
    "**Evaluation Metrics**\n",
    "\n",
    "- rmse:\n",
    "root mean squared error.\n",
    "tells how far off predictions are in the same units as the target.\n",
    "large errors have a bigger effect because they are squared.\n",
    "\n",
    "- mae:\n",
    "mean absolute error;\n",
    "shows the average size of the errors without caring if they are too high or too low.\n",
    "easy to understand because it is in the same units as the data\n",
    "\n",
    "- mape:\n",
    "mean absolute percentage error.\n",
    "shows the average error as a percent of the actual value.\n",
    "useful for comparing across scales but can look very large if the actual values are small.\n",
    "\n",
    "- r2:\n",
    "coefficient of determination:\n",
    "shows how much of the variation in the data is explained by the model.\n",
    "values close to 1 mean the model explains most of the variation.\n",
    "values near 0 mean the model is no better than guessing the mean.\n",
    "negative values mean the model is worse than just predicting the mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21349335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to import r2_score from sklearn if not available set it to none\n",
    "#ugh\n",
    "try:\n",
    "    from sklearn.metrics import r2_score as _sk_r2\n",
    "except Exception:\n",
    "    _sk_r2 = None\n",
    "\n",
    "# ensure month_start exists on test_eval\n",
    "if 'month_start' not in test_eval.columns:\n",
    "    test_eval['month_start'] = test_eval['date'].values.astype('datetime64[M]')\n",
    "\n",
    "# aggregate to monthly totals in the test period\n",
    "monthly_test = (test_eval\n",
    "                .groupby('month_start', as_index=False)\n",
    "                .agg(amount=('amount','sum'),\n",
    "                     predicted_amount=('predicted_amount','sum'))\n",
    "                .sort_values('month_start'))\n",
    "\n",
    "# overall metrics on monthly totals\n",
    "monthly_tot_metrics = evaluate_regression_metrics(\n",
    "    monthly_test, actual_col='amount', pred_col='predicted_amount'\n",
    ")\n",
    "\n",
    "print(\"\\nmonthly totals metrics on test period\")\n",
    "print(monthly_tot_metrics)\n",
    "\n",
    "# per-month view with errors\n",
    "monthly_view = monthly_test.copy()\n",
    "monthly_view['error'] = monthly_view['predicted_amount'] - monthly_view['amount']\n",
    "monthly_view['abs_error'] = monthly_view['error'].abs()\n",
    "monthly_view['ape_%'] = 100 * monthly_view['abs_error'] / monthly_view['amount'].replace(0, pd.NA)\n",
    "\n",
    "print(\"\\nmonthly totals comparison\")\n",
    "print(monthly_view.to_string(index=False))\n",
    "\n",
    "\n",
    "# ensure we have an ijb_budget_page column even if data is one hot\n",
    "def _ensure_ijb_budget_page_col(df, prefix='ijb_budget_page_'):\n",
    "    if 'ijb_budget_page' in df.columns:\n",
    "        return df\n",
    "    ohe_cols = [c for c in df.columns if c.startswith(prefix)]\n",
    "    if not ohe_cols:\n",
    "        return df  # nothing to do\n",
    "    row_sums = df[ohe_cols].sum(axis=1)\n",
    "    max_col = df[ohe_cols].idxmax(axis=1)\n",
    "    df = df.copy()\n",
    "    df['ijb_budget_page'] = np.where(row_sums.eq(0), pd.NA, max_col.str[len(prefix):])\n",
    "    return df\n",
    "\n",
    "test_eval = _ensure_ijb_budget_page_col(test_eval, prefix='ijb_budget_page_')\n",
    "\n",
    "# aggregate to monthly totals per ijb budget page\n",
    "monthly_bp = (test_eval\n",
    "              .groupby(['month_start','ijb_budget_page'], as_index=False)\n",
    "              .agg(amount=('amount','sum'),\n",
    "                   predicted_amount=('predicted_amount','sum'))\n",
    "              .sort_values(['month_start','ijb_budget_page']))\n",
    "\n",
    "# overall metrics across all months per ijb budget page\n",
    "def _metrics_over_group(df):\n",
    "    y, yhat = df['amount'].to_numpy(float), df['predicted_amount'].to_numpy(float)\n",
    "    return pd.Series({'RMSE': _rmse(y,yhat),\n",
    "                      'MAE': _mae(y,yhat),\n",
    "                      'MAPE': _mape(y,yhat),\n",
    "                      'R2': _r2(y,yhat)})\n",
    "\n",
    "bp_overall_metrics = (monthly_bp\n",
    "                      .groupby('ijb_budget_page', dropna=False, as_index=False)\n",
    "                      .apply(lambda g: _metrics_over_group(g))\n",
    "                      .reset_index(drop=True))\n",
    "\n",
    "print(\"\\noverall metrics on monthly totals by ijb budget page\")\n",
    "print(bp_overall_metrics.sort_values('RMSE'))\n",
    "\n",
    "# per month per ijb budget page table with errors and row wise metrics\n",
    "bp_view = monthly_bp.copy()\n",
    "bp_view['error'] = bp_view['predicted_amount'] - bp_view['amount']\n",
    "bp_view['abs_error'] = bp_view['error'].abs()\n",
    "bp_view['mape_%'] = 100 * bp_view['abs_error'] / bp_view['amount'].replace(0, pd.NA)\n",
    "# for a single aggregated row rmse equals mae equals abs_error\n",
    "bp_view['mae'] = bp_view['abs_error']\n",
    "bp_view['rmse'] = bp_view['abs_error']\n",
    "\n",
    "print(\"\\nmonthly totals comparison by ijb budget page\")\n",
    "print(bp_view[['month_start','ijb_budget_page','amount','predicted_amount',\n",
    "               'error','abs_error','mae','rmse','mape_%']].to_string(index=False))\n",
    "\n",
    "# optional metrics per month per ijb budget page using the evaluator\n",
    "def _safe_group_apply(df, groups, func):\n",
    "    gb = df.groupby(groups, dropna=False, as_index=False)\n",
    "    try:\n",
    "        return gb.apply(func, include_groups=False).reset_index(drop=True)\n",
    "    except TypeError:\n",
    "        return gb.apply(func).reset_index(drop=True)\n",
    "\n",
    "bp_per_month_metrics = _safe_group_apply(\n",
    "    monthly_bp,\n",
    "    ['ijb_budget_page','month_start'],\n",
    "    lambda g: pd.Series({'RMSE': _rmse(g['amount'], g['predicted_amount']),\n",
    "                         'MAE': _mae(g['amount'], g['predicted_amount']),\n",
    "                         'MAPE': _mape(g['amount'], g['predicted_amount']),\n",
    "                         'R2': _r2(g['amount'], g['predicted_amount'])})\n",
    ")\n",
    "\n",
    "print(\"\\nper month metrics by ijb budget page first 30 rows\")\n",
    "print(bp_per_month_metrics.head(30))\n",
    "\n",
    "# function to calculate root mean squared error\n",
    "# this tells how far off predictions are in the same units as the target\n",
    "def _rmse(y, yhat): \n",
    "    return float(np.sqrt(np.mean((y - yhat) ** 2)))\n",
    "\n",
    "# function to calculate mean absolute error\n",
    "# this gives the average size of the errors ignoring direction\n",
    "def _mae(y, yhat):  \n",
    "    return float(np.mean(np.abs(y - yhat)))\n",
    "\n",
    "# function to calculate mean absolute percentage error\n",
    "#this shows average error size as a percent of the actual values\n",
    "#if actual values are close to zero it skips them to avoid division issues\n",
    "def _mape(y, yhat, eps=1e-8):\n",
    "    y, yhat = np.asarray(y, float), np.asarray(yhat, float)\n",
    "    mask = np.abs(y) > eps\n",
    "    if not np.any(mask): \n",
    "        return float(np.nan)\n",
    "    return float(np.mean(np.abs((y[mask] - yhat[mask]) / y[mask])) * 100.0)\n",
    "\n",
    "#function to calculate r2\n",
    "#this measures how much of the variation in the data is explained by the model\n",
    "#if sklearn is available it uses that otherwise it calculates manually\n",
    "def _r2(y, yhat):\n",
    "    y, yhat = np.asarray(y, float), np.asarray(yhat, float)\n",
    "    if _sk_r2 is not None:\n",
    "        return float(_sk_r2(y, yhat))\n",
    "    ss_res, ss_tot = np.sum((y - yhat) ** 2), np.sum((y - np.mean(y)) ** 2)\n",
    "    return float(1 - ss_res / ss_tot) if ss_tot > 0 else float(np.nan)\n",
    "\n",
    "#main function to compute all metrics\n",
    "#takes a dataframe and names of the actual and predicted columns\n",
    "# can also group by colums like month or cost centre to get metrics per group\n",
    "def evaluate_regression_metrics(df, actual_col, pred_col, group_cols=None):\n",
    "    def _agg(grp):\n",
    "        y, yhat = grp[actual_col].to_numpy(float), grp[pred_col].to_numpy(float)\n",
    "        return pd.Series({\n",
    "            'RMSE': _rmse(y,yhat),\n",
    "            'MAE': _mae(y,yhat),\n",
    "            'MAPE': _mape(y,yhat),\n",
    "            'R2': _r2(y,yhat)\n",
    "        })\n",
    "    if group_cols:\n",
    "        use_groups = [g for g in group_cols if g in df.columns]\n",
    "        if not use_groups:\n",
    "            return _agg(df).to_frame().T\n",
    "        out = df.groupby(use_groups, dropna=False, as_index=False).apply(_agg).reset_index(drop=True)\n",
    "        return out\n",
    "    return _agg(df).to_frame().T\n",
    "\n",
    "#two decimal places\n",
    "pd.set_option(\"display.float_format\", \"{:,.2f}\".format)\n",
    "\n",
    "# calculate metrics at row level each row is a record in the test set\n",
    "row_metrics = evaluate_regression_metrics(test_eval, actual_col=\"amount\", pred_col=\"predicted_amount\")\n",
    "print(\"\\nrow level metrics on test set\")\n",
    "print(row_metrics)\n",
    "\n",
    "#calculate metrics at monthly totals level comparing actual and predicted monthly sums\n",
    "month_metrics = evaluate_regression_metrics(monthly_cmp, actual_col=\"amount\", pred_col=\"predicted_amount\")\n",
    "print(\"\\nmonthly total metrics\")\n",
    "print(month_metrics)\n",
    "\n",
    "#calculate metrics at cost centre by month level if cc column is present\n",
    "if \"cc\" in test_eval.columns:\n",
    "    cc_month_metrics = evaluate_regression_metrics(\n",
    "        test_eval,\n",
    "        actual_col=\"amount\",\n",
    "        pred_col=\"predicted_amount\",\n",
    "        group_cols=[\"cc\",\"month_start\"]\n",
    "    )\n",
    "    # show the first 20 rows so the printout is not too large\n",
    "    print(\"\\ncc by month metrics first 20 rows\")\n",
    "    print(cc_month_metrics.sample(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab50c507",
   "metadata": {},
   "source": [
    "**Interpreting Results** \n",
    "\n",
    "interpretation of results:\n",
    "- the model performs well on many cost centres with r2 values around 0.9 and errors that are stable month to month\n",
    "- the model is weaker for some cost centres where r2 drops or goes negative and where percentage errors become very large\n",
    "- these high percentage errors usually happen when the actual amounts are very small so even small absolute misses look big in percent terms\n",
    "\n",
    "what the model is good at:\n",
    "- it tracks overall spending patterns well\n",
    "- it explains most of the variation in larger cost centres\n",
    "- it gives a reliable baseline forecast at total and monthly levels\n",
    "\n",
    "what the model is bad at:\n",
    "- it struggles with small or volatile cost centres where actuals fluctuate or are near zero\n",
    "- it sometimes gives forecasts that are worse than a simple average for these difficult cases\n",
    "- it should be combined with business knowledge and adjustments for the more unusual cost centres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1f34e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#monthly totals for each month and year\n",
    "# First, convert string values to float\n",
    "df['payperiod'] = df['payperiod'].astype(float)\n",
    "\n",
    "# Then convert float to integer (now safe)\n",
    "df['payperiod'] = df['payperiod'].astype(int)\n",
    "\n",
    "amount_month= df.groupby(['year','payperiod'])['amount'].sum()\n",
    "print(amount_month)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa84e79e",
   "metadata": {},
   "source": [
    "# Un-encoding and saving as CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df21b2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b48bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper to decode encoded values back into readable form\n",
    "def decode_cc_and_budget(frame, inv_maps, drop_ohe=True, ohe_prefix='ijb_budget_page_'):\n",
    "   \n",
    "    #makes a copy of the dataframe\n",
    "    #turns cc codes back into their original labels using the inverse mapping\n",
    "    #turns budget page one hot encoded columns back into a single budget page column\n",
    "  \n",
    "    out = frame.copy()\n",
    "\n",
    "    #decode cc if it exists in both the data and the inverse mapping\n",
    "    if 'cc' in out.columns and 'cc' in inv_maps:\n",
    "        #convert cc column to integers then map back to original codes\n",
    "        cc_int = pd.to_numeric(out['cc'], errors='coerce').round().astype('Int64')\n",
    "        out['cc'] = cc_int.map(inv_maps['cc'])\n",
    "\n",
    "    #find all columns that start with the one hot prefix\n",
    "    ohe_cols = [c for c in out.columns if c.startswith(ohe_prefix)]\n",
    "    if ohe_cols:\n",
    "        #calculate the sum per row to see if any one hot flags are set\n",
    "        row_sums = out[ohe_cols].sum(axis=1)\n",
    "        #find which column has the maximum value per row\n",
    "        max_col = out[ohe_cols].idxmax(axis=1)\n",
    "        #remove the prefix to get the original category name\n",
    "        out['ijb_budget_page'] = np.where(\n",
    "            row_sums.eq(0),\n",
    "            pd.NA,\n",
    "            max_col.str[len(ohe_prefix):]\n",
    "        )\n",
    "\n",
    "        #drop the one hot columns if requested\n",
    "        if drop_ohe:\n",
    "            out.drop(columns=ohe_cols, inplace=True)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3570fce",
   "metadata": {},
   "source": [
    "Saving future detail df (all rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e305aa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to make csv files using unencoding elper above\n",
    "#Rebuild human-readable columns then save every forecasted row.\n",
    "future_detail_decoded = decode_cc_and_budget(future_detail, inv_mappings, drop_ohe=True)\n",
    "\n",
    "#also decode other label-encoded cols\n",
    "for col in ['payrollgroup', 'element', 'job']:\n",
    "    if col in future_detail_decoded.columns and col in inv_mappings:\n",
    "        tmp = pd.to_numeric(future_detail_decoded[col], errors='coerce').round().astype('Int64')\n",
    "        future_detail_decoded[col] = tmp.map(inv_mappings[col])\n",
    "\n",
    "# ensure clean date formatting\n",
    "for dcol in ['date', 'month_start']:\n",
    "    if dcol in future_detail_decoded.columns:\n",
    "        future_detail_decoded[dcol] = pd.to_datetime(future_detail_decoded[dcol]).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "#save yayy\n",
    "future_detail_path = 'forecast_detail_rows.csv'\n",
    "future_detail_decoded.to_csv(future_detail_path, index=False)\n",
    "print(f\"Saved detailed forecast rows to: {future_detail_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2208d0ac",
   "metadata": {},
   "source": [
    "Saving monthly toatals df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e60ebb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Forecast of monthly totals\n",
    "# You already computed `future_monthly` (with diagnostics). Keep it tidy and save.\n",
    "future_monthly_out = future_monthly.copy()\n",
    "\n",
    "# nice column names\n",
    "future_monthly_out = future_monthly_out.rename(columns={'predicted_total': 'forecast_total'})\n",
    "\n",
    "# date formatting\n",
    "future_monthly_out['month_start'] = pd.to_datetime(future_monthly_out['month_start']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# choose what you want in the CSV (include diagnostics if useful)\n",
    "monthly_cols = ['month_start', 'forecast_total', 'base_month', 'base_rowcount', 'future_rowcount', 'note']\n",
    "monthly_cols = [c for c in monthly_cols if c in future_monthly_out.columns]\n",
    "future_monthly_out = future_monthly_out[monthly_cols]\n",
    "\n",
    "# save\n",
    "future_monthly_path = 'forecast_monthly_totals.csv'\n",
    "future_monthly_out.to_csv(future_monthly_path, index=False)\n",
    "print(f\"Saved monthly totals to: {future_monthly_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b47be9",
   "metadata": {},
   "source": [
    "Saving forecast vs budgets df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28a359b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#forecast vs budget\n",
    "# `plot_df` already holds budget, forecast, and variances for the budgeted months.\n",
    "budget_out = plot_df.copy()\n",
    "budget_out = budget_out.rename(columns={'predicted_total': 'forecast_total'})\n",
    "budget_out['month_start'] = pd.to_datetime(budget_out['month_start']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "budget_cols = ['month_start', 'budget', 'forecast_total', 'variance', 'variance_%']\n",
    "budget_cols = [c for c in budget_cols if c in budget_out.columns]\n",
    "budget_out = budget_out[budget_cols]\n",
    "\n",
    "# save\n",
    "budget_csv_path = 'forecast_vs_budget.csv'\n",
    "budget_out.to_csv(budget_csv_path, index=False)\n",
    "print(f\"Saved forecast vs budget to: {budget_csv_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
