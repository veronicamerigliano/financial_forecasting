{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1e2193",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import datasets and load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import imageio\n",
    "import os\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "import itertools\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_17=pd.read_csv('2017A.csv')\n",
    "df_18=pd.read_csv('2018A.csv')\n",
    "df_19=pd.read_csv('2019A.csv')\n",
    "df_20=pd.read_csv('2020A.csv')\n",
    "df_21=pd.read_csv('2021A.csv')\n",
    "df_22=pd.read_csv('2022A.csv')\n",
    "df_23=pd.read_csv('2023A.csv')\n",
    "df_24=pd.read_csv('2024D.csv')\n",
    "df_25=pd.read_csv('2025A.csv')\n",
    "\n",
    "\n",
    "\n",
    "print(df_17.head(30))\n",
    "print(df_17.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2926826",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_22.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de61369",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_23.rename(columns={\n",
    "    'Payroll[Org]': 'Org',\n",
    "    'Payroll[CC]': 'CC',\n",
    "    'Payroll[Subj]': 'Subj',\n",
    "    'Payroll[S1]': 'S1',\n",
    "    'Payroll[S2]': 'S2',\n",
    "    'Payroll[Reference]': 'Reference',\n",
    "    'Payroll[Employee Num]': 'Employee Num',\n",
    "    'Payroll[Employee Name]': 'Employee Name',\n",
    "    'Payroll[Payroll Group]': 'Payroll Group',\n",
    "    'Payroll[Element]': 'Element',\n",
    "    'Payroll[Hours]': 'Hours',\n",
    "    'Payroll[Job & Home CC]': 'Job & Home CC',\n",
    "    'Payroll[Period]': 'Period',\n",
    "    'Calendar[Year]': 'Year',\n",
    "    '[SumAmount]': 'Amount'\n",
    "}, inplace=True)\n",
    "\n",
    "df_24.rename(columns={\n",
    "    'Payroll[Org]': 'Org',\n",
    "    'Payroll[CC]': 'CC',\n",
    "    'Payroll[Subj]': 'Subj',\n",
    "    'Payroll[S1]': 'S1',\n",
    "    'Payroll[S2]': 'S2',\n",
    "    'Payroll[Reference]': 'Reference',\n",
    "    'Payroll[Employee Num]': 'Employee Num',\n",
    "    'Payroll[Employee Name]': 'Employee Name',\n",
    "    'Payroll[Payroll Group]': 'Payroll Group',\n",
    "    'Payroll[Element]': 'Element',\n",
    "    'Payroll[Hours]': 'Hours',\n",
    "    'Payroll[Job & Home CC]': 'Job & Home CC',\n",
    "    'Payroll[Period]': 'Period',\n",
    "    'Calendar[Year]': 'Year',\n",
    "    '[SumAmount]': 'Amount'\n",
    "}, inplace=True)\n",
    "\n",
    "df_25.rename(columns={\n",
    "    'Payroll[Org]': 'Org',\n",
    "    'Payroll[CC]': 'CC',\n",
    "    'Payroll[Subj]': 'Subj',\n",
    "    'Payroll[S1]': 'S1',\n",
    "    'Payroll[S2]': 'S2',\n",
    "    'Payroll[Reference]': 'Reference',\n",
    "    'Payroll[Employee Num]': 'Employee Num',\n",
    "    'Payroll[Employee Name]': 'Employee Name',\n",
    "    'Payroll[Payroll Group]': 'Payroll Group',\n",
    "    'Payroll[Element]': 'Element',\n",
    "    'Payroll[Hours]': 'Hours',\n",
    "    'Payroll[Job & Home CC]': 'Job & Home CC',\n",
    "    'Payroll[Period]': 'Period',\n",
    "    'Calendar[Year]': 'Year',\n",
    "    '[SumAmount]': 'Amount'\n",
    "}, inplace=True)\n",
    "\n",
    "df_17.rename(columns={\n",
    "    'Payroll[Org]': 'Org',\n",
    "    'Payroll[CC]': 'CC',\n",
    "    'Payroll[Subj]': 'Subj',\n",
    "    'Payroll[S1]': 'S1',\n",
    "    'Payroll[S2]': 'S2',\n",
    "    'Payroll[Reference]': 'Reference',\n",
    "    'Payroll[Employee Num]': 'Employee Num',\n",
    "    'Payroll[Employee Name]': 'Employee Name',\n",
    "    'Payroll[Payroll Group]': 'Payroll Group',\n",
    "    'Payroll[Element]': 'Element',\n",
    "    'Payroll[Hours]': 'Hours',\n",
    "    'Payroll[Job & Home CC]': 'Job & Home CC',\n",
    "    'Payroll[Period]': 'Period',\n",
    "    'Calendar[Year]': 'Year',\n",
    "    '[SumAmount]': 'Amount'\n",
    "}, inplace=True)\n",
    "\n",
    "df_18.rename(columns={\n",
    "    'Payroll[Org]': 'Org',\n",
    "    'Payroll[CC]': 'CC',\n",
    "    'Payroll[Subj]': 'Subj',\n",
    "    'Payroll[S1]': 'S1',\n",
    "    'Payroll[S2]': 'S2',\n",
    "    'Payroll[Reference]': 'Reference',\n",
    "    'Payroll[Employee Num]': 'Employee Num',\n",
    "    'Payroll[Employee Name]': 'Employee Name',\n",
    "    'Payroll[Payroll Group]': 'Payroll Group',\n",
    "    'Payroll[Element]': 'Element',\n",
    "    'Payroll[Hours]': 'Hours',\n",
    "    'Payroll[Job & Home CC]': 'Job & Home CC',\n",
    "    'Payroll[Period]': 'Period',\n",
    "    'Calendar[Year]': 'Year',\n",
    "    '[SumAmount]': 'Amount'\n",
    "}, inplace=True)\n",
    "\n",
    "df_19.rename(columns={\n",
    "    'Payroll[Org]': 'Org',\n",
    "    'Payroll[CC]': 'CC',\n",
    "    'Payroll[Subj]': 'Subj',\n",
    "    'Payroll[S1]': 'S1',\n",
    "    'Payroll[S2]': 'S2',\n",
    "    'Payroll[Reference]': 'Reference',\n",
    "    'Payroll[Employee Num]': 'Employee Num',\n",
    "    'Payroll[Employee Name]': 'Employee Name',\n",
    "    'Payroll[Payroll Group]': 'Payroll Group',\n",
    "    'Payroll[Element]': 'Element',\n",
    "    'Payroll[Hours]': 'Hours',\n",
    "    'Payroll[Job & Home CC]': 'Job & Home CC',\n",
    "    'Payroll[Period]': 'Period',\n",
    "    'Calendar[Year]': 'Year',\n",
    "    '[SumAmount]': 'Amount'\n",
    "}, inplace=True)\n",
    "\n",
    "df_20.rename(columns={\n",
    "    'Payroll[Org]': 'Org',\n",
    "    'Payroll[CC]': 'CC',\n",
    "    'Payroll[Subj]': 'Subj',\n",
    "    'Payroll[S1]': 'S1',\n",
    "    'Payroll[S2]': 'S2',\n",
    "    'Payroll[Reference]': 'Reference',\n",
    "    'Payroll[Employee Num]': 'Employee Num',\n",
    "    'Payroll[Employee Name]': 'Employee Name',\n",
    "    'Payroll[Payroll Group]': 'Payroll Group',\n",
    "    'Payroll[Element]': 'Element',\n",
    "    'Payroll[Hours]': 'Hours',\n",
    "    'Payroll[Job & Home CC]': 'Job & Home CC',\n",
    "    'Payroll[Period]': 'Period',\n",
    "    'Calendar[Year]': 'Year',\n",
    "    '[SumAmount]': 'Amount'\n",
    "}, inplace=True)\n",
    "\n",
    "df_21.rename(columns={\n",
    "    'Payroll[Org]': 'Org',\n",
    "    'Payroll[CC]': 'CC',\n",
    "    'Payroll[Subj]': 'Subj',\n",
    "    'Payroll[S1]': 'S1',\n",
    "    'Payroll[S2]': 'S2',\n",
    "    'Payroll[Reference]': 'Reference',\n",
    "    'Payroll[Employee Num]': 'Employee Num',\n",
    "    'Payroll[Employee Name]': 'Employee Name',\n",
    "    'Payroll[Payroll Group]': 'Payroll Group',\n",
    "    'Payroll[Element]': 'Element',\n",
    "    'Payroll[Hours]': 'Hours',\n",
    "    'Payroll[Job & Home CC]': 'Job & Home CC',\n",
    "    'Payroll[Period]': 'Period',\n",
    "    'Calendar[Year]': 'Year',\n",
    "    '[SumAmount]': 'Amount'\n",
    "}, inplace=True)\n",
    "\n",
    "df_22.rename(columns={\n",
    "    'Payroll[Org]': 'Org',\n",
    "    'Payroll[CC]': 'CC',\n",
    "    'Payroll[Subj]': 'Subj',\n",
    "    'Payroll[S1]': 'S1',\n",
    "    'Payroll[S2]': 'S2',\n",
    "    'Payroll[Reference]': 'Reference',\n",
    "    'Payroll[Employee Num]': 'Employee Num',\n",
    "    'Payroll[Employee Name]': 'Employee Name',\n",
    "    'Payroll[Payroll Group]': 'Payroll Group',\n",
    "    'Payroll[Element]': 'Element',\n",
    "    'Payroll[Hours]': 'Hours',\n",
    "    'Payroll[Job & Home CC]': 'Job & Home CC',\n",
    "    'Payroll[Period]': 'Period',\n",
    "    'Calendar[Year]': 'Year',\n",
    "    '[SumAmount]': 'Amount'\n",
    "}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a7e4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#if i want to see output not truncated add this:df.infor()\n",
    "pd.set_option('display.max_rows', None)       # Show all rows\n",
    "pd.set_option('display.max_columns', None)    # Show all columns\n",
    "pd.set_option('display.width', None)          # Prevent line wrapping\n",
    "pd.set_option('display.max_colwidth', None)   #show full column content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b39803d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [df_17, df_18, df_19, df_20, df_21, df_22, df_23, df_24, df_25]\n",
    "for df in dfs:\n",
    "    # Extract the first 4 digits from the Year string\n",
    "    df['Year'] = df['Year'].str.slice(0, 4)\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a283439c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Amount']].head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79a57a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making negative values (that int he og dataset are in brackets) show as negative\n",
    "df['Amount'] = (\n",
    "    df['Amount']\n",
    "    .astype(str)\n",
    "    .str.replace(r'\\((.*?)\\)', r'-\\1', regex=True)  # Convert (100) â†’ -100\n",
    "    .astype(float)  # Convert to float\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06d6fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Amount']].head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43b8148",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b88945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency of each 'ref', sorted from least to most\n",
    "ref_counts_sorted = df['Reference'].value_counts().sort_values()\n",
    "print(ref_counts_sorted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94de0455",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping columns Year S1 S2\n",
    "df= df.drop(columns=[ 'S1','Org', 'S2',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e95369",
   "metadata": {},
   "outputs": [],
   "source": [
    "##df stats\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad71c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df info (dtype, columns, entries etc)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e51a002",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for nulls\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214a0532",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping all nulls except for those in hours and job &home cc\n",
    "df=df.dropna(subset=df.columns.difference([\"Hours\", \"Job & Home CC\"]))\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37280298",
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing columns names so they are easier to type\n",
    "df.columns= ['cc', 'subj', 'reference', 'employeenum', 'employeename', 'payrollgroup', 'payperiod', 'element', 'hours', 'job', 'period', 'year', 'amount']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63744cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = pd.to_numeric(df['year'], errors='coerce').astype('Int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7280ce69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling nulls in job columns with 'no description'\n",
    "df['job'] = df['job'].fillna('no description')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20a8854",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for remaining nulls\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4910b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorting by hours to see whats up with the nulls in hours\n",
    "df_sorted = df.sort_values(by='hours', ascending=False)\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(df_sorted.tail(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16eef6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  fill hours null with 0.0 because of issues with uploading time sheets from itrent\n",
    "#  to oracle a lot of the info in 'hours' is missing but it wont be necessary anyway so its fine\n",
    "df['hours'] = df['hours'].fillna(0)\n",
    "print(df.tail(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656e8ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique pay period entries\n",
    "df['payperiod'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9930f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['payrollgroup'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f81b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funtion for monthly grand total for all time\n",
    "def monthly_grand_total(df):\n",
    "    # Ensure 'amount' is numeric\n",
    "    df['amount'] = pd.to_numeric(df['amount'], errors='coerce')\n",
    "    \n",
    "    # Group by month and sum the amounts\n",
    "    monthly_total = df.groupby('payperiod')['amount'].sum()\n",
    "    \n",
    "    # Sort by month number (01 to 12)\n",
    "    monthly_total = monthly_total.sort_index()\n",
    "    \n",
    "    return monthly_total\n",
    "print(monthly_grand_total(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b00d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#info\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22f8540",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for duplicares\n",
    "df.duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1fcb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df['amount'] < 0].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6037f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#yay no more nulls!\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34533b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35313137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#monthly totals for each month and year\n",
    "# First, convert string values to float\n",
    "df['payperiod'] = df['payperiod'].astype(float)\n",
    "\n",
    "# Then convert float to integer (now safe)\n",
    "df['payperiod'] = df['payperiod'].astype(int)\n",
    "\n",
    "amount_month= df.groupby(['year','payperiod'])['amount'].sum()\n",
    "print(amount_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d0fe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905d6e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4920f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS \n",
    "# identifying outliers first try (too many outliers given need to narrow it down a lot, giving better results with very high z score of 10 )\n",
    "threshold = 10  # Z-score threshold\n",
    "outlier_indices = []  # store indices of all outliers across years\n",
    "\n",
    "for year in range(2017, 2026):\n",
    "    df_year = df[df['year'] == year]\n",
    "    \n",
    "    if df_year.empty:\n",
    "        print(f\"\\nYear {year}: No data available.\")\n",
    "        continue\n",
    "\n",
    "    mean = np.mean(df_year['amount'])\n",
    "    std = np.std(df_year['amount'])\n",
    "\n",
    "    if std == 0:\n",
    "        print(f\"\\nYear {year}: Standard deviation is zero. No outliers can be computed.\")\n",
    "        continue\n",
    "\n",
    "    z_scores = (df_year['amount'] - mean) / std\n",
    "\n",
    "    # Get the outlier rows and their indices\n",
    "    outliers = df_year[np.abs(z_scores) > threshold]\n",
    "    outlier_indices.extend(outliers.index)  # collect indices\n",
    "\n",
    "    # preview\n",
    "    outlier_count = len(outliers)\n",
    "    print(f\"\\nYear: {year}\")\n",
    "    print(f\"Mean: {mean}\")\n",
    "    print(f\"Standard Deviation: {std}\")\n",
    "    print(f\"Number of Outliers: {outlier_count}\")\n",
    "    print(\"Outliers:\")\n",
    "    print(outliers[['amount', 'payperiod', 'job', 'employeename']].to_string(index=False)\n",
    "          if outlier_count > 0 else \"None\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f622018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all collected outlier rows\n",
    "df = df.drop(index=outlier_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d750ac9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#identifying extreme outliers for each year more specific to 0.001% extreme outliers\n",
    "#loop through each year from 2017 to 2025\n",
    "for year in range(2017, 2026):\n",
    "    #filter the dataset to only include rows for the current year\n",
    "    df_year = df[df['year'] == year]\n",
    "    \n",
    "    #if no data skip to the next\n",
    "    if df_year.empty:\n",
    "        print(f\"\\nYear {year}: No data available.\")\n",
    "        continue\n",
    "\n",
    "    #calculate percentile cutoffs to define extreme outliers\n",
    "    #these are the lowest 0.001% and highest 0.001% of values\n",
    "    lower_bound = df_year['amount'].quantile(0.00001)   #low values\n",
    "    upper_bound = df_year['amount'].quantile(0.99999)  #high values\n",
    "\n",
    "    #identify extreme outliers based on these percentiles\n",
    "    #keep only the most extreme rows that fall outside cutoff range\n",
    "    extreme_outliers = df_year[\n",
    "        (df_year['amount'] < lower_bound) | \n",
    "        (df_year['amount'] > upper_bound)\n",
    "    ][['amount', 'payperiod', 'reference']] #slect only key columns for clarity\n",
    "\n",
    "    #display results for the current year\n",
    "    print(f\"\\nyear: {year}\")\n",
    "    print(f\"lower bound (0.001% percentile): {lower_bound}\")\n",
    "    print(f\"upper bound (99.999% percentile): {upper_bound}\")\n",
    "    print(f\"number of extreme outliers: {len(extreme_outliers)}\")\n",
    "    print(\"extreme outliers:\")\n",
    "\n",
    "    #print the extreme outliers table or'None' if there are none\n",
    "    print(extreme_outliers.to_string(index=False) if not extreme_outliers.empty else \"None\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7ca93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#specific outliers for 20203\n",
    "threshold = 10  # Z-score threshold\n",
    "outlier_indices2023 = []  # store indices of outliers for 2023\n",
    "\n",
    "# Filter data for 2023\n",
    "df_2023 = df[df['year'] == 2023]\n",
    "\n",
    "if df_2023.empty:\n",
    "    print(\"Year 2023: No data available.\")\n",
    "else:\n",
    "    mean = np.mean(df_2023['amount'])\n",
    "    std = np.std(df_2023['amount'])\n",
    "\n",
    "    if std == 0:\n",
    "        print(\"Year 2023: Standard deviation is zero. No outliers can be computed.\")\n",
    "    else:\n",
    "        z_scores = (df_2023['amount'] - mean) / std\n",
    "\n",
    "        # Identify outliers and collect indices\n",
    "        outliers = df_2023[np.abs(z_scores) > threshold]\n",
    "        outlier_indices.extend(outliers.index)\n",
    "\n",
    "        outlier_count = len(outliers)\n",
    "\n",
    "        print(\"\\nYear: 2023\")\n",
    "        print(f\"Mean: {mean}\")\n",
    "        print(f\"Standard Deviation: {std}\")\n",
    "        print(f\"Number of Outliers: {outlier_count}\")\n",
    "        print(\"Outliers:\")\n",
    "        print(outliers[['amount', 'payperiod', 'reference', 'job', 'employeename']].to_string(index=False)\n",
    "              if outlier_count > 0 else \"None\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7714bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all collected outlier rows\n",
    "df = df.drop(index=outlier_indices2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882af4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.drop(columns=['employeename', 'employeenum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b474480b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedf2852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436670ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique 'cc' values\n",
    "print(\"Number of unique cc values:\", df['cc'].nunique())\n",
    "\n",
    "# Frequency/count of each unique 'cc' value\n",
    "cc_counts = df['cc'].value_counts().sort_values(ascending=True)\n",
    "print(cc_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b707e955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic stats\n",
    "print(df['amount'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e3cbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#monthly totals for each month and year\n",
    "# First, convert string values to float\n",
    "df['payperiod'] = df['payperiod'].astype(float)\n",
    "\n",
    "# Then convert float to integer (now safe)\n",
    "df['payperiod'] = df['payperiod'].astype(int)\n",
    "\n",
    "amount_month= df.groupby(['year','payperiod'])['amount'].sum()\n",
    "print(amount_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10722c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c92eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete the # when im ready to save this as a new document\n",
    "df.to_csv(\"USE_THIS.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75afcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparison of 2017 with 2024\n",
    "two_year_compare=df[df['year'].isin([2017,2018,2019,2020,2021,2022,2023,2024])]\n",
    "\n",
    "amount_totals = two_year_compare.groupby(['year'])['amount'].sum().reset_index()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "sns.lineplot(data=amount_totals, x='year',y='amount', palette='rocket', marker='o' )\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('year')\n",
    "plt.ylabel('amount')\n",
    "plt.title('comaprison of 2017 to 2024')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c41151",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all years continuous graph\n",
    "df_filtered = df[(df['year'] >= 2017) & (df['year'] <= 2025)].copy()\n",
    "# Convert payperiod to numeric (float), coerce errors if any bad values\n",
    "df_filtered['payperiod'] = pd.to_numeric(df_filtered['payperiod'], errors='coerce')\n",
    "\n",
    "# Then convert to int\n",
    "df_filtered['month'] = df_filtered['payperiod'].astype('Int64')  # 'Int64' allows NaNs if any\n",
    "\n",
    "# Create a datetime column for the first day of each month\n",
    "df_filtered['date'] = pd.to_datetime(dict(year=df_filtered['year'], month=df_filtered['month'], day=1))\n",
    "\n",
    "# Group by the date and sum amount\n",
    "monthly_totals = df_filtered.groupby('date')['amount'].sum()\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# ... your code up to monthly_totals ...\n",
    "\n",
    "# Ensure a continuous monthly index (start-of-month) from 2017-01 to 2025-12\n",
    "full_idx = pd.date_range('2017-01-01', '2025-12-01', freq='MS')\n",
    "monthly_totals = monthly_totals.reindex(full_idx, fill_value=0)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(30, 10))\n",
    "ax.plot(monthly_totals.index, monthly_totals.values, marker='o', linestyle='-')\n",
    "ax.set_title('Total Amount per Month from 2017 to 2025')\n",
    "ax.set_xlabel('Month')\n",
    "ax.set_ylabel('Total Amount')\n",
    "ax.grid(True)\n",
    "\n",
    "# Show month names on the x-axis\n",
    "ax.xaxis.set_major_locator(mdates.MonthLocator(interval=1))             # every month\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))             # e.g., \"Jan 2019\"\n",
    "fig.autofmt_xdate()                                                     # rotate + align nicely\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763e6469",
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplots\n",
    "# We already have df_filtered with 'year', 'month', and 'amount'\n",
    "\n",
    "# Group by year and month, summing amounts\n",
    "monthly_totals_per_year = df_filtered.groupby(['year', 'month'])['amount'].sum().reset_index()\n",
    "\n",
    "# Plot boxplot: x = year, y = monthly total amounts\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.boxplot(data=monthly_totals_per_year, x='year', y='amount')\n",
    "\n",
    "plt.title('Distribution of Monthly Total Amounts per Year (2017-2025)')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Monthly Total Amount')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c746463",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete the # when im ready to save this as a new document\n",
    "#df.to_csv(\"cleaned_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3db74d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#most ocmmon cc doe august 2022\n",
    "# Step 1: Filter for August 2022\n",
    "# August = payperiod 5.0, year = 2022\n",
    "\n",
    "august_2022 = df[(df['year'] == 2022) & (df['payperiod'] == 5.0)]\n",
    "\n",
    "# Step 2: Find the most common CC\n",
    "most_common_cc = august_2022['cc'].value_counts().idxmax()\n",
    "count = august_2022['cc'].value_counts().max()\n",
    "\n",
    "print(f\"The most common CC in August 2022 is: {most_common_cc} (count: {count})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb21f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cc with the highest total amoun in august 2017\n",
    "# Step 1: Filter for August 2017 (payperiod 5.0)\n",
    "august_2017 = df[(df['year'] == 2017) & (df['payperiod'] == 5.0)]\n",
    "\n",
    "# Step 2: Group by CC and sum the amounts\n",
    "cc_totals = august_2017.groupby('cc')['amount'].sum()\n",
    "\n",
    "# Step 3: Get the CC with the highest total amount\n",
    "top_cc = cc_totals.idxmax()\n",
    "top_amount = cc_totals.max()\n",
    "\n",
    "print(f\"The CC with the highest total amount in August 2017 is: {top_cc} (Total Amount: {top_amount:,.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64da77a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TOP 5 cc with highest totals\n",
    "print(cc_totals.sort_values(ascending=False).head(5))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
